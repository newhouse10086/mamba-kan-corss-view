#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FSRA-VMKè®­ç»ƒè„šæœ¬
ç»“åˆVision Mambaå’ŒKANæŠ€æœ¯çš„è·¨è§†è§’å›¾åƒåŒ¹é…æ¨¡å‹è®­ç»ƒ

åŸºäºæ‚¨çš„åˆ†æï¼Œå®ç°FSRA-VMK: Vision Mamba Kolmogorov Network
- O(n)çº¿æ€§å¤æ‚åº¦çš„Vision Mambaç¼–ç å™¨
- Kolmogorov-Arnold Networksæ³¨æ„åŠ›æœºåˆ¶
- åŒå‘è·¨è§†è§’ç‰¹å¾å¯¹é½
"""

import os
import sys
import time
import argparse
import datetime
import numpy as np
import random
from typing import Dict, List, Tuple, Optional

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
import torch.backends.cudnn as cudnn

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from models.vmamba_kan_fsra import FSRAVMambaKAN
from dataset.university1652_dataset import University1652Dataset
from utils.losses import CrossEntropyLabelSmooth, TripletLoss, ContrastiveLoss
from utils.metrics import compute_recall_at_k, compute_map, compute_cmc
from utils.lr_scheduler import WarmupMultiStepLR

def set_seed(seed: int = 42):
    """è®¾ç½®éšæœºç§å­ä¿è¯å®éªŒå¯é‡å¤æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    cudnn.deterministic = True
    cudnn.benchmark = False

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='FSRA-VMK Training')
    
    # é€šç”¨é…ç½®
    parser.add_argument('--config', type=str, default='', help='YAML é…ç½®æ–‡ä»¶è·¯å¾„')

    # æ•°æ®é›†å‚æ•°
    parser.add_argument('--data_dir', type=str, default='./data/University-1652',
                        help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--num_classes', type=int, default=1652,
                        help='ç±»åˆ«æ•°é‡')
    parser.add_argument('--image_size', type=int, default=256,
                        help='å›¾åƒå°ºå¯¸')
    parser.add_argument('--query_mode', type=str, default='drone_to_satellite',
                        choices=['drone_to_satellite', 'satellite_to_drone'],
                        help='æŸ¥è¯¢æ¨¡å¼')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--embed_dim', type=int, default=512,
                        help='ç‰¹å¾ç»´åº¦')
    parser.add_argument('--depth', type=int, default=12,
                        help='VMambaæ·±åº¦')
    parser.add_argument('--kan_grid_size', type=int, default=5,
                        help='KANç½‘æ ¼å¤§å°')
    parser.add_argument('--num_heads', type=int, default=8,
                        help='æ³¨æ„åŠ›å¤´æ•°')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--batch_size', type=int, default=32,
                        help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--epochs', type=int, default=300,
                        help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=0.0001,
                        help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=5e-4,
                        help='æƒé‡è¡°å‡')
    parser.add_argument('--warmup_epochs', type=int, default=10,
                        help='å­¦ä¹ ç‡é¢„çƒ­è½®æ•°')
    
    # æŸå¤±å‡½æ•°æƒé‡
    parser.add_argument('--id_loss_weight', type=float, default=1.0,
                        help='IDæŸå¤±æƒé‡')
    parser.add_argument('--triplet_loss_weight', type=float, default=1.0,
                        help='ä¸‰å…ƒç»„æŸå¤±æƒé‡')
    parser.add_argument('--contrastive_loss_weight', type=float, default=0.5,
                        help='å¯¹æ¯”æŸå¤±æƒé‡')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--save_dir', type=str, default='./checkpoints',
                        help='æ¨¡å‹ä¿å­˜ç›®å½•')
    parser.add_argument('--log_dir', type=str, default='./logs',
                        help='æ—¥å¿—ä¿å­˜ç›®å½•')
    parser.add_argument('--resume', type=str, default='',
                        help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--eval_step', type=int, default=10,
                        help='è¯„ä¼°é—´éš”')
    parser.add_argument('--save_step', type=int, default=50,
                        help='ä¿å­˜é—´éš”')
    parser.add_argument('--seed', type=int, default=42,
                        help='éšæœºç§å­')
    parser.add_argument('--device', type=str, default='cuda',
                        help='è®­ç»ƒè®¾å¤‡')
    
    return parser.parse_args()

class FSRATrainer:
    """FSRA-VMKè®­ç»ƒå™¨"""
    
    def __init__(self, args):
        self.args = args
        self.device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(args.save_dir, exist_ok=True)
        os.makedirs(args.log_dir, exist_ok=True)
        
        # åˆ›å»ºTensorBoardè®°å½•å™¨
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        self.writer = SummaryWriter(os.path.join(args.log_dir, f'fsra_vmk_{timestamp}'))
        
        # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        self._init_dataloader()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._init_model()
        
        # åˆå§‹åŒ–æŸå¤±å‡½æ•°
        self._init_loss_functions()
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
        self._init_optimizer()
        
        # è®­ç»ƒçŠ¶æ€
        self.start_epoch = 0
        self.best_map = 0.0
        self.best_recall1 = 0.0
        
        # æ¢å¤è®­ç»ƒ
        if args.resume:
            self._load_checkpoint(args.resume)
    
    def _init_dataloader(self):
        """åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨"""
        print("ğŸ”„ åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨...")
        
        # è®­ç»ƒé›†
        train_dataset = University1652Dataset(
            data_dir=self.args.data_dir,
            mode='train',
            query_mode=self.args.query_mode,
            image_size=self.args.image_size,
            augment=True
        )
        
        self.train_loader = DataLoader(
            train_dataset,
            batch_size=self.args.batch_size,
            shuffle=True,
            num_workers=4,
            pin_memory=True,
            drop_last=True
        )
        
        # æµ‹è¯•é›† - æŸ¥è¯¢é›†
        query_dataset = University1652Dataset(
            data_dir=self.args.data_dir,
            mode='query',
            query_mode=self.args.query_mode,
            image_size=self.args.image_size,
            augment=False
        )
        
        self.query_loader = DataLoader(
            query_dataset,
            batch_size=self.args.batch_size,
            shuffle=False,
            num_workers=4,
            pin_memory=True
        )
        
        # æµ‹è¯•é›† - ç”»å»Šé›†
        gallery_dataset = University1652Dataset(
            data_dir=self.args.data_dir,
            mode='gallery',
            query_mode=self.args.query_mode,
            image_size=self.args.image_size,
            augment=False
        )
        
        self.gallery_loader = DataLoader(
            gallery_dataset,
            batch_size=self.args.batch_size,
            shuffle=False,
            num_workers=4,
            pin_memory=True
        )
        
        print(f"âœ… è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
        print(f"âœ… æŸ¥è¯¢é›†: {len(query_dataset)} æ ·æœ¬")
        print(f"âœ… ç”»å»Šé›†: {len(gallery_dataset)} æ ·æœ¬")
    
    def _init_model(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        print("ğŸ”„ åˆå§‹åŒ–FSRA-VMKæ¨¡å‹...")
        
        self.model = FSRAVMambaKAN(
            num_classes=self.args.num_classes,
            embed_dim=self.args.embed_dim,
            depth=self.args.depth,
            kan_grid_size=self.args.kan_grid_size,
            num_heads=self.args.num_heads,
            image_size=self.args.image_size
        ).to(self.device)
        
        # ç»Ÿè®¡å‚æ•°é‡
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        
        print(f"âœ… æ¨¡å‹å‚æ•°æ€»é‡: {total_params:,}")
        print(f"âœ… å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,}")
        print(f"âœ… æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")
    
    def _init_loss_functions(self):
        """åˆå§‹åŒ–æŸå¤±å‡½æ•°"""
        print("ğŸ”„ åˆå§‹åŒ–æŸå¤±å‡½æ•°...")
        
        # IDåˆ†ç±»æŸå¤±ï¼ˆå¸¦æ ‡ç­¾å¹³æ»‘ï¼‰
        self.id_loss = CrossEntropyLabelSmooth(
            num_classes=self.args.num_classes,
            epsilon=0.1
        ).to(self.device)
        
        # ä¸‰å…ƒç»„æŸå¤±
        self.triplet_loss = TripletLoss(
            margin=0.3,
            distance='euclidean'
        ).to(self.device)
        
        # å¯¹æ¯”æŸå¤±
        self.contrastive_loss = ContrastiveLoss(
            temperature=0.07
        ).to(self.device)
        
        print("âœ… æŸå¤±å‡½æ•°åˆå§‹åŒ–å®Œæˆ")
    
    def _init_optimizer(self):
        """åˆå§‹åŒ–ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        print("ğŸ”„ åˆå§‹åŒ–ä¼˜åŒ–å™¨...")
        
        # å‚æ•°åˆ†ç»„
        backbone_params = []
        classifier_params = []
        
        for name, param in self.model.named_parameters():
            if 'classifier' in name:
                classifier_params.append(param)
            else:
                backbone_params.append(param)
        
        # AdamWä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW([
            {'params': backbone_params, 'lr': self.args.lr},
            {'params': classifier_params, 'lr': self.args.lr * 10}  # åˆ†ç±»å™¨ä½¿ç”¨æ›´å¤§å­¦ä¹ ç‡
        ], weight_decay=self.args.weight_decay)
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆå¸¦é¢„çƒ­ï¼‰
        self.scheduler = WarmupMultiStepLR(
            self.optimizer,
            milestones=[150, 250],
            gamma=0.1,
            warmup_epochs=self.args.warmup_epochs,
            warmup_factor=0.1
        )
        
        print(f"âœ… ä¼˜åŒ–å™¨: AdamW, å­¦ä¹ ç‡: {self.args.lr}")
        print(f"âœ… å­¦ä¹ ç‡è°ƒåº¦: é¢„çƒ­{self.args.warmup_epochs}è½®ï¼Œ[150, 250]è½®è¡°å‡")
    
    def _load_checkpoint(self, checkpoint_path: str):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        print(f"ğŸ”„ åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
        
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        self.start_epoch = checkpoint['epoch'] + 1
        self.best_map = checkpoint.get('best_map', 0.0)
        self.best_recall1 = checkpoint.get('best_recall1', 0.0)
        
        print(f"âœ… æ£€æŸ¥ç‚¹åŠ è½½å®Œæˆï¼Œä»ç¬¬{self.start_epoch}è½®å¼€å§‹è®­ç»ƒ")
    
    def _save_checkpoint(self, epoch: int, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_map': self.best_map,
            'best_recall1': self.best_recall1,
            'args': self.args
        }
        
        # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
        checkpoint_path = os.path.join(self.args.save_dir, f'checkpoint_epoch_{epoch}.pth')
        torch.save(checkpoint, checkpoint_path)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_path = os.path.join(self.args.save_dir, 'best_model.pth')
            torch.save(checkpoint, best_path)
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_path}")
    
    def train_epoch(self, epoch: int) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        
        losses = {
            'total': 0.0,
            'id': 0.0,
            'triplet': 0.0,
            'contrastive': 0.0
        }
        
        num_batches = len(self.train_loader)
        
        for batch_idx, (images, labels, _) in enumerate(self.train_loader):
            images = images.to(self.device)  # [B, C, H, W]
            labels = labels.to(self.device)  # [B]
            
            # å‰å‘ä¼ æ’­
            outputs = self.model(images)
            logits = outputs['logits']      # [B, num_classes]
            features = outputs['features']  # [B, embed_dim]
            
            # è®¡ç®—æŸå¤±
            id_loss = self.id_loss(logits, labels)
            triplet_loss = self.triplet_loss(features, labels)
            contrastive_loss = self.contrastive_loss(features, labels)
            
            # æ€»æŸå¤±
            total_loss = (self.args.id_loss_weight * id_loss + 
                         self.args.triplet_loss_weight * triplet_loss + 
                         self.args.contrastive_loss_weight * contrastive_loss)
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            total_loss.backward()
            self.optimizer.step()
            
            # ç´¯è®¡æŸå¤±
            losses['total'] += total_loss.item()
            losses['id'] += id_loss.item()
            losses['triplet'] += triplet_loss.item()
            losses['contrastive'] += contrastive_loss.item()
            
            # æ‰“å°è¿›åº¦
            if batch_idx % 50 == 0:
                print(f"Epoch [{epoch}/{self.args.epochs}] "
                      f"Batch [{batch_idx}/{num_batches}] "
                      f"Loss: {total_loss.item():.4f} "
                      f"ID: {id_loss.item():.4f} "
                      f"Triplet: {triplet_loss.item():.4f} "
                      f"Contrast: {contrastive_loss.item():.4f}")
        
        # è®¡ç®—å¹³å‡æŸå¤±
        for key in losses:
            losses[key] /= num_batches
        
        return losses
    
    @torch.no_grad()
    def evaluate(self, epoch: int) -> Dict[str, float]:
        """è¯„ä¼°æ¨¡å‹"""
        print("ğŸ”„ å¼€å§‹è¯„ä¼°...")
        self.model.eval()
        
        # æå–æŸ¥è¯¢ç‰¹å¾
        query_features = []
        query_labels = []
        
        for images, labels, _ in self.query_loader:
            images = images.to(self.device)
            outputs = self.model(images)
            features = outputs['features']
            
            query_features.append(features.cpu())
            query_labels.append(labels)
        
        query_features = torch.cat(query_features, dim=0)  # [N_q, D]
        query_labels = torch.cat(query_labels, dim=0)      # [N_q]
        
        # æå–ç”»å»Šç‰¹å¾
        gallery_features = []
        gallery_labels = []
        
        for images, labels, _ in self.gallery_loader:
            images = images.to(self.device)
            outputs = self.model(images)
            features = outputs['features']
            
            gallery_features.append(features.cpu())
            gallery_labels.append(labels)
        
        gallery_features = torch.cat(gallery_features, dim=0)  # [N_g, D]
        gallery_labels = torch.cat(gallery_labels, dim=0)      # [N_g]
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        metrics = {}
        
        # Recall@K
        for k in [1, 5, 10]:
            recall_k = compute_recall_at_k(query_features, gallery_features, 
                                         query_labels, gallery_labels, k=k)
            metrics[f'Recall@{k}'] = recall_k
        
        # mAP
        map_score = compute_map(query_features, gallery_features, 
                               query_labels, gallery_labels)
        metrics['mAP'] = map_score
        
        # CMCæ›²çº¿
        cmc = compute_cmc(query_features, gallery_features, 
                         query_labels, gallery_labels, max_rank=20)
        for i, rank in enumerate([1, 5, 10, 20]):
            if i < len(cmc):
                metrics[f'CMC@{rank}'] = cmc[i]
        
        print("ğŸ“Š è¯„ä¼°ç»“æœ:")
        for metric, value in metrics.items():
            print(f"  {metric}: {value:.4f}")
        
        return metrics
    
    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        print("ğŸš€ å¼€å§‹è®­ç»ƒFSRA-VMKæ¨¡å‹...")
        print(f"ğŸ“Š è®­ç»ƒé…ç½®:")
        print(f"  - æ•°æ®é›†: University-1652")
        print(f"  - æŸ¥è¯¢æ¨¡å¼: {self.args.query_mode}")
        print(f"  - æ‰¹æ¬¡å¤§å°: {self.args.batch_size}")
        print(f"  - è®­ç»ƒè½®æ•°: {self.args.epochs}")
        print(f"  - å­¦ä¹ ç‡: {self.args.lr}")
        print(f"  - è®¾å¤‡: {self.device}")
        
        start_time = time.time()
        
        for epoch in range(self.start_epoch, self.args.epochs):
            epoch_start_time = time.time()
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_losses = self.train_epoch(epoch)
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler.step()
            current_lr = self.scheduler.get_last_lr()[0]
            
            # è®°å½•è®­ç»ƒæŸå¤±
            for loss_name, loss_value in train_losses.items():
                self.writer.add_scalar(f'Train/Loss_{loss_name}', loss_value, epoch)
            self.writer.add_scalar('Train/LearningRate', current_lr, epoch)
            
            # è¯„ä¼°æ¨¡å‹
            if (epoch + 1) % self.args.eval_step == 0 or epoch == self.args.epochs - 1:
                eval_metrics = self.evaluate(epoch)
                
                # è®°å½•è¯„ä¼°æŒ‡æ ‡
                for metric_name, metric_value in eval_metrics.items():
                    self.writer.add_scalar(f'Eval/{metric_name}', metric_value, epoch)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
                is_best = False
                if eval_metrics['mAP'] > self.best_map:
                    self.best_map = eval_metrics['mAP']
                    self.best_recall1 = eval_metrics['Recall@1']
                    is_best = True
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if (epoch + 1) % self.args.save_step == 0 or is_best:
                    self._save_checkpoint(epoch, is_best)
            
            epoch_time = time.time() - epoch_start_time
            print(f"â±ï¸  Epoch {epoch} å®Œæˆï¼Œç”¨æ—¶: {epoch_time:.2f}s, "
                  f"å­¦ä¹ ç‡: {current_lr:.6f}")
            print("-" * 80)
        
        total_time = time.time() - start_time
        print(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼æ€»ç”¨æ—¶: {total_time/3600:.2f}å°æ—¶")
        print(f"ğŸ† æœ€ä½³ç»“æœ: mAP={self.best_map:.4f}, Recall@1={self.best_recall1:.4f}")
        
        self.writer.close()

def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()

    # å¦‚æœæä¾›äº† YAML é…ç½®æ–‡ä»¶ï¼ŒåŠ è½½å¹¶è¦†ç›–é»˜è®¤å‚æ•°
    if args.config:
        import yaml, argparse
        with open(args.config, 'r', encoding='utf-8') as f:
            cfg_dict = yaml.safe_load(f)

        # é€’å½’æ‰å¹³åŒ–å­—å…¸
        def flatten_dict(d, parent_key='', sep='.'):  # simple flatten
            items = {}
            for k, v in d.items():
                new_key = f"{parent_key}{sep}{k}" if parent_key else k
                if isinstance(v, dict):
                    items.update(flatten_dict(v, new_key, sep=sep))
                else:
                    items[new_key] = v
            return items

        flat_cfg = flatten_dict(cfg_dict)

        for key, value in flat_cfg.items():
            # å°†åµŒå¥—é”®è½¬æ¢ä¸ºå±æ€§åï¼Œä¾‹å¦‚ training.batch_size -> batch_size
            attr = key.split('.')[-1]
            if hasattr(args, attr):
                setattr(args, attr, value)
        print(f"ğŸ”§ ä»é…ç½®æ–‡ä»¶ {args.config} åŠ è½½å‚æ•°å¹¶è¦†ç›–é»˜è®¤å€¼")
    
    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)
    
    # æ‰“å°é…ç½®
    print("=" * 80)
    print("ğŸš€ FSRA-VMK: Vision Mamba Kolmogorov Network")
    print("ğŸ“‹ è®­ç»ƒé…ç½®:")
    for arg, value in sorted(vars(args).items()):
        print(f"  {arg}: {value}")
    print("=" * 80)
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    trainer = FSRATrainer(args)
    trainer.train()

if __name__ == '__main__':
    main() 