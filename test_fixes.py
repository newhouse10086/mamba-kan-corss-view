#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯FSRA-VMKä¿®å¤æ˜¯å¦æ­£ç¡®
"""

import torch
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_dataset():
    """æµ‹è¯•æ•°æ®é›†æ˜¯å¦æ­£ç¡®è¿”å›droneå’Œsatelliteå›¾åƒ"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®é›†...")
    
    try:
        from dataset.university1652_dataset import University1652Dataset
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
        dataset = University1652Dataset(
            data_dir="./data",
            mode='train',
            query_mode='drone_to_satellite',
            image_size=256,
            augment=False
        )
        
        if len(dataset) == 0:
            print("âš ï¸ æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„")
            return False
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        sample = dataset[0]
        print(f"âœ… æ•°æ®é›†æ ·æœ¬æ ¼å¼: {len(sample)} ä¸ªå…ƒç´ ")
        
        if len(sample) == 4:
            drone_img, satellite_img, class_id, path = sample
            print(f"âœ… Droneå›¾åƒå½¢çŠ¶: {drone_img.shape}")
            print(f"âœ… Satelliteå›¾åƒå½¢çŠ¶: {satellite_img.shape}")
            print(f"âœ… ç±»åˆ«ID: {class_id}")
            return True
        else:
            print(f"âŒ æ•°æ®æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›4ä¸ªå…ƒç´ ï¼Œå¾—åˆ°{len(sample)}ä¸ª")
            return False
            
    except Exception as e:
        print(f"âŒ æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model():
    """æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­"""
    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹...")
    
    try:
        from models.vmamba_kan_fsra import FSRAVMambaKAN
        
        # åˆ›å»ºæ¨¡å‹
        model = FSRAVMambaKAN(
            num_classes=10,  # æµ‹è¯•ç”¨å°æ•°å€¼
            dim=256,
            num_layers=6,
            num_heads=8,
            image_size=256
        )
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        test_input = torch.randn(4, 3, 256, 256)
        
        with torch.no_grad():
            output = model(test_input)
        
        print(f"âœ… æ¨¡å‹è¾“å‡ºæ ¼å¼: {type(output)}")
        if isinstance(output, dict):
            print(f"âœ… Logitså½¢çŠ¶: {output['logits'].shape}")
            print(f"âœ… Featureså½¢çŠ¶: {output['features'].shape}")
            return True
        else:
            print(f"âŒ æ¨¡å‹è¾“å‡ºæ ¼å¼é”™è¯¯")
            return False
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_losses():
    """æµ‹è¯•æŸå¤±å‡½æ•°"""
    print("\nğŸ§ª æµ‹è¯•æŸå¤±å‡½æ•°...")
    
    try:
        from utils.losses import CrossEntropyLabelSmooth, TripletLoss, ContrastiveLoss
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        features = torch.randn(8, 256)
        labels = torch.tensor([0, 0, 1, 1, 2, 2, 3, 3])
        logits = torch.randn(8, 10)
        
        # æµ‹è¯•IDæŸå¤±
        id_loss = CrossEntropyLabelSmooth(num_classes=10)
        id_loss_value = id_loss(logits, labels)
        print(f"âœ… ID Loss: {id_loss_value.item():.4f}")
        
        # æµ‹è¯•TripletæŸå¤±
        triplet_loss = TripletLoss()
        triplet_loss_value = triplet_loss(features, labels)
        print(f"âœ… Triplet Loss: {triplet_loss_value.item():.4f}")
        
        # æµ‹è¯•ContrastiveæŸå¤±
        contrastive_loss = ContrastiveLoss(temperature=0.07)
        contrastive_loss_value = contrastive_loss(features, labels)
        print(f"âœ… Contrastive Loss: {contrastive_loss_value.item():.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æŸå¤±å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_sampler():
    """æµ‹è¯•é‡‡æ ·å™¨"""
    print("\nğŸ§ª æµ‹è¯•é‡‡æ ·å™¨...")
    
    try:
        from utils.sampler import RandomIdentitySampler
        
        # åˆ›å»ºæµ‹è¯•æ ‡ç­¾
        labels = [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2] * 10  # é‡å¤ç¡®ä¿è¶³å¤Ÿæ ·æœ¬
        
        sampler = RandomIdentitySampler(
            labels=labels,
            batch_size=12,
            num_instances=4
        )
        
        print(f"âœ… é‡‡æ ·å™¨é•¿åº¦: {len(sampler)}")
        
        # æµ‹è¯•é‡‡æ ·
        sample_iter = iter(sampler)
        batch_indices = []
        for i, idx in enumerate(sample_iter):
            batch_indices.append(idx)
            if i >= 11:  # è·å–ä¸€ä¸ªbatch
                break
        
        batch_labels = [labels[idx] for idx in batch_indices]
        unique_labels = set(batch_labels)
        print(f"âœ… Batchæ ‡ç­¾: {batch_labels}")
        print(f"âœ… å”¯ä¸€ç±»åˆ«æ•°: {len(unique_labels)}")
        
        return len(unique_labels) >= 2  # è‡³å°‘æœ‰2ä¸ªä¸åŒç±»åˆ«
        
    except Exception as e:
        print(f"âŒ é‡‡æ ·å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•FSRA-VMKä¿®å¤...")
    
    tests = [
        ("æ•°æ®é›†", test_dataset),
        ("æ¨¡å‹", test_model), 
        ("æŸå¤±å‡½æ•°", test_losses),
        ("é‡‡æ ·å™¨", test_sampler)
    ]
    
    results = []
    for name, test_func in tests:
        try:
            result = test_func()
            results.append(result)
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"{status} {name}æµ‹è¯•")
        except Exception as e:
            print(f"âŒ {name}æµ‹è¯•å¼‚å¸¸: {e}")
            results.append(False)
    
    print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“: {sum(results)}/{len(results)} é€šè¿‡")
    
    if all(results):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒäº†ã€‚")
        print("\nğŸš€ æ¨èè®­ç»ƒå‘½ä»¤:")
        print("python train.py \\")
        print("    --config configs/fsra_vmk_config.yaml \\")
        print("    --data_dir ./data \\")
        print("    --query_mode drone_to_satellite \\")
        print("    --lr 0.0005 \\")
        print("    --warmup_epochs 5 \\")
        print("    --triplet_loss_weight 0.1 \\")
        print("    --contrastive_loss_weight 0.0")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ç»„ä»¶ã€‚")

if __name__ == "__main__":
    main() 